{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ushabolimera/Retail-Sales-Prediction/blob/main/Retail_Sales_Prediction_Capstone_Project(_Part_1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOGC-qoyhJeX"
      },
      "source": [
        "# <b><u> Project Title : Sales Prediction : Predicting sales of a major store chain Rossmann</u></b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y06xIdG26kRF"
      },
      "source": [
        "## <b> Problem Description </b>\n",
        "\n",
        "### Rossmann operates over 3,000 drug stores in 7 European countries. Currently, Rossmann store managers are tasked with predicting their daily sales for up to six weeks in advance. Store sales are influenced by many factors, including promotions, competition, school and state holidays, seasonality, and locality. With thousands of individual managers predicting sales based on their unique circumstances, the accuracy of results can be quite varied.\n",
        "\n",
        "### You are provided with historical sales data for 1,115 Rossmann stores. The task is to forecast the \"Sales\" column for the test set. Note that some stores in the dataset were temporarily closed for refurbishment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWeU1f9bwqQq"
      },
      "source": [
        "## <b> Data Description </b>\n",
        "\n",
        "### <b>Rossmann Stores Data.csv </b> - historical data including Sales\n",
        "### <b>store.csv </b> - supplemental information about the stores\n",
        "\n",
        "\n",
        "### <b><u>Data fields</u></b>\n",
        "### Most of the fields are self-explanatory. The following are descriptions for those that aren't.\n",
        "\n",
        "* #### Id - an Id that represents a (Store, Date) duple within the test set\n",
        "* #### Store - a unique Id for each store\n",
        "* #### Sales - the turnover for any given day (this is what you are predicting)\n",
        "* #### Customers - the number of customers on a given day\n",
        "* #### Open - an indicator for whether the store was open: 0 = closed, 1 = open\n",
        "* #### StateHoliday - indicates a state holiday. Normally all stores, with few exceptions, are closed on state holidays. Note that all schools are closed on public holidays and weekends. a = public holiday, b = Easter holiday, c = Christmas, 0 = None\n",
        "* #### SchoolHoliday - indicates if the (Store, Date) was affected by the closure of public schools\n",
        "* #### StoreType - differentiates between 4 different store models: a, b, c, d\n",
        "* #### Assortment - describes an assortment level: a = basic, b = extra, c = extended\n",
        "* #### CompetitionDistance - distance in meters to the nearest competitor store\n",
        "* #### CompetitionOpenSince[Month/Year] - gives the approximate year and month of the time the nearest competitor was opened\n",
        "* #### Promo - indicates whether a store is running a promo on that day\n",
        "* #### Promo2 - Promo2 is a continuing and consecutive promotion for some stores: 0 = store is not participating, 1 = store is participating\n",
        "* #### Promo2Since[Year/Week] - describes the year and calendar week when the store started participating in Promo2\n",
        "* #### PromoInterval - describes the consecutive intervals Promo2 is started, naming the months the promotion is started anew. E.g. \"Feb,May,Aug,Nov\" means each round starts in February, May, August, November of any given year for that store"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Approach**\n",
        "* **Business Problem:** \n",
        " This project involves solving a real-world business problem of sales forecasting and building up a machine learning model for the same. \n",
        "Our goal here is to forecast the sales for six weeks for each store and find out the factors influencing it and recommend ways in order to improve the numbers.\n",
        "* **Data Collection and Preprocessing**\n",
        "\n",
        "* **Exploratory Data Analysis**\n",
        "* **Feature Engineering**\n",
        "* **Modeling**\n",
        "\n",
        "* **Model Performance and Evaluation**\n",
        "* **Store wise Sales Predictions**\n",
        "* **Conclusion**"
      ],
      "metadata": {
        "id": "X58GhXBRJj9a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Collection and Preprocessing**"
      ],
      "metadata": {
        "id": "mnh4oW3yOtAM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dByMsuzT8Tnw"
      },
      "outputs": [],
      "source": [
        "#Importing important libraries and modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "plt.rcParams.update({'figure.figsize':(8,5),'figure.dpi':100})\n",
        "from datetime import datetime\n",
        "\n",
        "import warnings    \n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIBSDo5rSTw7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82b51b96-0052-4c9f-d310-68d239c6dce3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#mounting the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdueGD6mSV8P"
      },
      "outputs": [],
      "source": [
        "#Reading the data from csv files from both datasets\n",
        "Rsd_df= pd.read_csv(\"/content/drive/MyDrive/Alma Better/Projects/SML Regression - Retail Sales Prediction/Rossmann Stores Data.csv\")\n",
        "store_df=pd.read_csv(\"/content/drive/MyDrive/Alma Better/Projects/SML Regression - Retail Sales Prediction/store.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfqbcktvS2h3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "98f5e56c-9ac4-4db7-d145-7f6ed4e24d0e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Store  DayOfWeek        Date  Sales  Customers  Open  Promo StateHoliday  \\\n",
              "0      1          5  2015-07-31   5263        555     1      1            0   \n",
              "1      2          5  2015-07-31   6064        625     1      1            0   \n",
              "2      3          5  2015-07-31   8314        821     1      1            0   \n",
              "3      4          5  2015-07-31  13995       1498     1      1            0   \n",
              "4      5          5  2015-07-31   4822        559     1      1            0   \n",
              "\n",
              "   SchoolHoliday  \n",
              "0              1  \n",
              "1              1  \n",
              "2              1  \n",
              "3              1  \n",
              "4              1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b14d2b19-f453-4bdd-a52e-fee215964603\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Store</th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>Date</th>\n",
              "      <th>Sales</th>\n",
              "      <th>Customers</th>\n",
              "      <th>Open</th>\n",
              "      <th>Promo</th>\n",
              "      <th>StateHoliday</th>\n",
              "      <th>SchoolHoliday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2015-07-31</td>\n",
              "      <td>5263</td>\n",
              "      <td>555</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>2015-07-31</td>\n",
              "      <td>6064</td>\n",
              "      <td>625</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2015-07-31</td>\n",
              "      <td>8314</td>\n",
              "      <td>821</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>2015-07-31</td>\n",
              "      <td>13995</td>\n",
              "      <td>1498</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>2015-07-31</td>\n",
              "      <td>4822</td>\n",
              "      <td>559</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b14d2b19-f453-4bdd-a52e-fee215964603')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b14d2b19-f453-4bdd-a52e-fee215964603 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b14d2b19-f453-4bdd-a52e-fee215964603');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#Looking the Rossmann stores dataset\n",
        "Rsd_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUhgiQMbS5UP"
      },
      "outputs": [],
      "source": [
        "#Looking the stores dataset\n",
        "store_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWSL35P-TEsD"
      },
      "outputs": [],
      "source": [
        "#Getting the sales data information\n",
        "Rsd_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 1017209 rows and 9 columns in this dataset. There seems to be no null values in it. It has integer, datetime and object as data types."
      ],
      "metadata": {
        "id": "dMSiKfXaQQbv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9gxlrDVTxes"
      },
      "outputs": [],
      "source": [
        "#Getting the stores data information\n",
        "store_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 1115 rows and 10 columns. There are missing values in it and it is important to impute them with appropriate values in order to get good results later on."
      ],
      "metadata": {
        "id": "17nqLquAQbV-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCiBExAzUCup"
      },
      "outputs": [],
      "source": [
        "# Describing the sales dataset\n",
        "Rsd_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5RT2_34USCw"
      },
      "outputs": [],
      "source": [
        "# Describing the stores dataset\n",
        "store_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Missing Data Handling"
      ],
      "metadata": {
        "id": "nRwhiHVkQ2kE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1F5YSzv8UcLZ"
      },
      "outputs": [],
      "source": [
        "# Checking the null values \n",
        "Rsd_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqKGMt6BUkDg"
      },
      "outputs": [],
      "source": [
        "# Checking the null values \n",
        "store_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Out of 1115 entries there are missing values for the columns:\n",
        "* CompetitionDistance- distance in meters to the nearest competitor store, the distribution plot would give us an idea about the distances at which generally the stores are opened and we would impute the values accordingly.\n",
        "\n",
        "* CompetitionOpenSinceMonth- gives the approximate month of the time the nearest competitor was opened, mode of the column would tell us the most occuring month    \n",
        "* CompetitionOpenSinceYear-  gives the approximate year of the time the nearest competitor was opened, mode of the column would tell us the most occuring month    \n",
        "* Promo2SinceWeek, Promo2SinceYear and PromoInterval are NaN wherever Promo2 is 0 or False as can be seen in the first look of the dataset. They can be replaced with 0.     "
      ],
      "metadata": {
        "id": "7BP7SOmifwQR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97yOJWo6Uor7"
      },
      "outputs": [],
      "source": [
        "#distribution plot of competition distance\n",
        "sns.distplot(x=store_df['CompetitionDistance'])\n",
        "plt.xlabel('Competition Distance Distribution Plot')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3x3lGBOykPbx"
      },
      "source": [
        "It seems like most of the values of the CompetitionDistance are towards the right and the distribution is skewed on the right. Median is more robust to outlier effect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGHNF9lzVDl-"
      },
      "outputs": [],
      "source": [
        "# filling competition distance with the median value\n",
        "store_df[\"CompetitionDistance\"].fillna(store_df[\"CompetitionDistance\"].median(), inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sf3BGBE0nmxj"
      },
      "outputs": [],
      "source": [
        "store_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pHP3O0WoaQ6"
      },
      "outputs": [],
      "source": [
        "#distribution plot of CompetitionOpenSinceMonth\n",
        "sns.distplot(x=store_df['CompetitionOpenSinceMonth'])\n",
        "plt.xlabel('CompetitionOpenSinceMonth Distrubution plot')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TRTWKTFxWdO"
      },
      "source": [
        "Since it is like categorical column. Mode is the best central tendency to impute the values in this column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpnWUemfpIJF"
      },
      "outputs": [],
      "source": [
        "# filling competition open since month with the most occuring values of the columns i.e modes of those columns\n",
        "store_df['CompetitionOpenSinceMonth'].fillna(store_df['CompetitionOpenSinceMonth'].mode()[0],inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w00d3DMprZbp"
      },
      "outputs": [],
      "source": [
        "store_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LmN3MCUxmRv"
      },
      "outputs": [],
      "source": [
        "#distribution plot of CompetitionOpenSinceYear\n",
        "sns.distplot(x=store_df['CompetitionOpenSinceYear'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nWAxZ0ExTQ4"
      },
      "outputs": [],
      "source": [
        "# filling competition open since year with the most occuring values of the columns\n",
        "store_df['CompetitionOpenSinceYear'].fillna(store_df['CompetitionOpenSinceYear'].mode()[0],inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5faCACs6x2d5"
      },
      "outputs": [],
      "source": [
        "store_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ntKayAm4TVg"
      },
      "source": [
        "If we check Promo2, Promo2SinceWeek, Promo2SinceYear and PromoInterval columns, when Promo2 is '0' remaining columns have NaN values where Promo2 is 1 remaining columns have some values. So we can replace NaN values with 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wm_ltskRx48S"
      },
      "outputs": [],
      "source": [
        "# imputing the nan values of promo2 related columns with 0\n",
        "store_df['Promo2SinceWeek'].fillna(value=0, inplace=True)\n",
        "store_df['Promo2SinceYear'].fillna(value=0, inplace=True)\n",
        "store_df['PromoInterval'].fillna(value=0, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-E8jL4fIyB0y"
      },
      "outputs": [],
      "source": [
        "store_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Merging the two Datasets"
      ],
      "metadata": {
        "id": "FBAOAX-71OoK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xR7en4EP566j"
      },
      "outputs": [],
      "source": [
        "#merge the datasets on stores data\n",
        "df=Rsd_df.merge(right=store_df, on=\"Store\", how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dU317j_tXVb7"
      },
      "outputs": [],
      "source": [
        "#first five rows of the merged dataset\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptQrTx7WYHIM"
      },
      "outputs": [],
      "source": [
        "#shape of the dataframe\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUPeB7WAYKNl"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we observe the dataset, Date column is in object datatype so we need to change it to Datetime."
      ],
      "metadata": {
        "id": "LmyeQGF41y0y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzBWj_hHYMAz"
      },
      "outputs": [],
      "source": [
        "# importing datetime \n",
        "from datetime import datetime as dt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQ3IZ602YntA"
      },
      "outputs": [],
      "source": [
        "# Changing the datatype form string to datetime format\n",
        "df['Date']=pd.to_datetime(df[\"Date\"], format=\"%Y/%m/%d\")\n",
        "df['Date']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTE-YMYlZ7fL"
      },
      "outputs": [],
      "source": [
        "#Checking info\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtAQM_PHaOE1"
      },
      "outputs": [],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sn4pW7Puf3PF"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Exploratory Data Analysis\n",
        "\n",
        "Exploratory data analysis is a crucial part of data analysis. It involves exploring and analyzing the dataset given to find patterns, trends and conclusions to make better decisions related to the data, often using statistical graphics and other data visualization tools to summarize the results. Python libraries like pandas are used to explore the data and matplotlib and seaborn to visualize it. It includes analyzing what our dataset consists of. Exploring continuous as well as categorical variables and their influence on our dependent variable-'Sales'.\n",
        "\n",
        "\n",
        "\n",
        "Just by observing the head of the dataset and understanding the features involved in it,  the following hypotheses could be framed:\n",
        "\n",
        "* There's a feature called \"DayOfWeek\" with the values 1-7 denoting each day of the week. There would be a week off probably Sunday when the stores would be closed and we would get low overall sales.\n",
        "* Customers would have a positive correlation with Sales.\n",
        "* The Store type and Assortment strategy involved would be having a certain effect on sales as well. Some premium high quality products would fetch more revenue.\n",
        "* Promotion should be having a positive correlation with Sales.\n",
        "* Some stores were closed due to refurbishment, those would generate 0 revenue for that time period.\n",
        "* Stores are influenced by seasonality, probably before holidays sales would be high.\n",
        "\n",
        "Next step is to explore and see in a data driven way about the factors influencing Rossmann stores sales and how.\n"
      ],
      "metadata": {
        "id": "8w0bMufD2pPy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5yvLtFBgg5N"
      },
      "outputs": [],
      "source": [
        "# Let's check DayOfWeek coloumn\n",
        "df['DayOfWeek'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2tfhBzagEKN"
      },
      "outputs": [],
      "source": [
        "# plot between sales and open columns\n",
        "sns.barplot(x=\"Open\", y=\"Sales\", data=df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYvs6h8kk0dL"
      },
      "outputs": [],
      "source": [
        "# Relationship between Day of week and sales\n",
        "sns.barplot(x='DayOfWeek',y='Sales', data=df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ws4Di1GZnx8H"
      },
      "outputs": [],
      "source": [
        "## Relationship between Promo and sales\n",
        "sns.barplot(x='Promo',y='Sales', data=df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v14Ay4muoNly"
      },
      "outputs": [],
      "source": [
        "# Getting the unique values in State Holiday\n",
        "df['StateHoliday'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyHuCYbVofjF"
      },
      "outputs": [],
      "source": [
        "# Replacing the \"0\"(string) with 0\n",
        "df['StateHoliday'].replace({\"0\":0},inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAK38BYDq-Fc"
      },
      "outputs": [],
      "source": [
        "# Checking \n",
        "df['StateHoliday'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9rqV2JQsYNw"
      },
      "outputs": [],
      "source": [
        "### Relationship between Promo and sales\n",
        "sns.barplot(x=\"StateHoliday\",y=\"Sales\",data=df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqXBxT9-si_r"
      },
      "outputs": [],
      "source": [
        "#Relationship between SchoolHoliday and sales\n",
        "sns.barplot(x=\"SchoolHoliday\",y=\"Sales\",data=df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HG67EncAs32Z"
      },
      "outputs": [],
      "source": [
        "#Relationship between StoreType and sales\n",
        "sns.barplot(x=\"StoreType\",y=\"Sales\",data=df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6O8RtTqcxkoO"
      },
      "outputs": [],
      "source": [
        "#Relationship between Assortment and sales\n",
        "sns.barplot(x=\"Assortment\",y=\"Sales\",data=df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLAQkHUlyt-x"
      },
      "outputs": [],
      "source": [
        "#Relationship between CompetitionOpenSinceMonth and sales\n",
        "sns.barplot(x=\"CompetitionOpenSinceMonth\",y=\"Sales\",data=df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zxU3AXn0zNe"
      },
      "outputs": [],
      "source": [
        "#Relationship between CompetitionOpenSinceYear and sales\n",
        "sns.barplot(x=\"CompetitionOpenSinceYear\",y=\"Sales\",data=df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImdnmxSv3FM8"
      },
      "outputs": [],
      "source": [
        "#Relationship between Promo2 and sales\n",
        "sns.barplot(x=\"Promo2\",y=\"Sales\",data=df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FakT5gZL3plB"
      },
      "outputs": [],
      "source": [
        "#Relationship between Promo2SinceWeek and sales\n",
        "sns.barplot(x=\"Promo2SinceWeek\",y=\"Sales\",data=df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "koOoIZdb6HWd"
      },
      "outputs": [],
      "source": [
        "#Relationship between Promo2SinceYear and sales\n",
        "sns.barplot(x=\"Promo2SinceYear\",y=\"Sales\",data=df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Yg5Dz246een"
      },
      "outputs": [],
      "source": [
        "#Relationship between PromoInterval and sales\n",
        "sns.barplot(x=\"PromoInterval\",y=\"Sales\",data=df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORyGd3v1lwSG"
      },
      "source": [
        "####Observation:\n",
        "*  There were more sales on Monday, probably because shops generally remain closed on Sundays.\n",
        "* It could be seen that the Promo leads to more sales.\n",
        "* Normally all stores, with few exceptions, are closed on state holidays. Note that all schools are closed on public holidays and weekends. a = public holiday, b = Easter holiday, c = Christmas, 0 = None. Lowest of Sales were seen on state holidays especially on Christmas.\n",
        "* More stores were open on School Holidays than on State Holidays and hence had more sales than State Holidays.\n",
        "* On an average Store type B had the highest sales.\n",
        "* Highest average sales were seen with Assortment levels-b which is 'extra'.\n",
        "* With Promo2, slightly more sales were seen without it which indicates there are many stores not participating in promo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2RX-9zo69kw"
      },
      "outputs": [],
      "source": [
        "# open and storetype relationship \n",
        "#this indicates - Open suggests that whether the store was open or closed for refurbishment and weekends or holidays\n",
        "sns.barplot(x=df[\"Open\"],y=df['Sales'],hue=df[\"DayOfWeek\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpvenBXbrs4V"
      },
      "outputs": [],
      "source": [
        "#Lets see open, how many shops are open on which days \n",
        "#and this gives a counts of stores closed for refurbishment and suggests that most stores are closed on sunday\n",
        "sns.countplot(x=df[\"Open\"], hue=df[\"DayOfWeek\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dk3G1aOysdB0"
      },
      "source": [
        "Observation:\n",
        "This is a count plot of open shops according to the day of the week. It's clear that the number of shops open on Sundays were very less and hence low sales. Some shops were closed on weekdays as well accounting to the stores closed due to refurbishment or holidays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQeeEn7OsiRO"
      },
      "outputs": [],
      "source": [
        "#Let's check the relationship between store type, assortment levels and sales\n",
        "sns.barplot(x=df[\"StoreType\"],y=df['Sales'],hue=df[\"Assortment\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZXcS505s4sw"
      },
      "source": [
        "####Observation:\n",
        "The above bar plot shows that the store types a, c and d have only assortment level a and c. On the other hand the store type b has all the three kinds of assortment strategies, a reason why average sales were high for store type b stores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_dhrA4-s6Gn"
      },
      "outputs": [],
      "source": [
        "#Store Type and Sales Exploration\n",
        "store_type = df.groupby(\"StoreType\")[\"Sales\",\"Customers\"].sum().reset_index()\n",
        "store_type.sort_values([\"Sales\",\"Customers\"], ascending= False, inplace = True) # sorting into descending order to get higher values\n",
        "store_type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5W-PKoAmtN99"
      },
      "outputs": [],
      "source": [
        "#let's explore store type a bit and it's influence on sales\n",
        "df.groupby(\"StoreType\")[\"Sales\"].sum().plot.pie(title='Store Type and Sales', legend=True, autopct='%1.1f%%', shadow=True)\n",
        "plt.show()\n",
        "#customers and store type\n",
        "df.groupby(\"StoreType\")[\"Customers\"].sum().plot.pie(title='Customer Share', legend=True, autopct='%1.1f%%', shadow=True)\n",
        "plt.show()\n",
        "#store types in all of the dataset\n",
        "df[\"StoreType\"].value_counts().plot.pie(title='Share of Store Types', legend=True, autopct='%1.1f%%', shadow=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnZidROJt3_N"
      },
      "source": [
        "####Observation:\n",
        "* A bar plot represents an estimate of central tendency for a numeric variable with the height of each rectangle. Earlier it was seen that the store type b had the highest sales on an average because the default estimation function to the barplot is mean. \n",
        "* But upon further exploration it can be clearly observed that the highest sales belonged to the store type a due to the high number of type a stores in our dataset. Store type a and c had a similar kind of sales and customer share.\n",
        "* Interesting insight to note is that store type b with highest average sales and per store revenue generation looks healthy and a reason for that would be all three kinds of assortment strategies involved which was seen earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDDIVQeHvtue"
      },
      "outputs": [],
      "source": [
        "#creating features from the date\n",
        "df['Year'] = df['Date'].dt.year\n",
        "df['Month'] = df['Date'].dt.month\n",
        "df['WeekOfYear'] = df['Date'].dt.weekofyear\n",
        "df['DayOfYear'] = df['Date'].dt.dayofyear\n",
        "years = df['Year'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Continuous Features:"
      ],
      "metadata": {
        "id": "4_zvreS_6tBM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Sales with Time"
      ],
      "metadata": {
        "id": "_-jaBb3s6www"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RW6oTWSDydlF"
      },
      "outputs": [],
      "source": [
        "years"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9v7ar-Gye8u"
      },
      "outputs": [],
      "source": [
        "#sales over the years\n",
        "sales_df_2013 = df[df['Year']== 2013]\n",
        "sales_df_2014 = df[df['Year']==2014]\n",
        "sales_df_2015 = df[df['Year']== 2015]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAPAz0LfysRS"
      },
      "outputs": [],
      "source": [
        "#monthly sales\n",
        "sales_2013 = sales_df_2013.groupby('Month')['Sales'].sum().reset_index()\n",
        "sales_2014 = sales_df_2014.groupby('Month')['Sales'].sum().reset_index()\n",
        "sales_2015 = sales_df_2015.groupby('Month')['Sales'].sum().reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yL_cqAQPyvZc"
      },
      "outputs": [],
      "source": [
        "#plotting\n",
        "plt.plot(sales_2013.loc[:,'Sales'],label='2013',color='orange')\n",
        "plt.plot(sales_2014.loc[:,'Sales'],label='2014',color='blue')\n",
        "plt.plot(sales_2015.loc[:,'Sales'],label='2015',color='green')\n",
        "plt.title('Monthly Sales Over Years')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_kCrZX6y401"
      },
      "source": [
        "####Observation:\n",
        "Sales rise up by the end of the year before the holidays. Sales for 2014 went down there for a couple months - July to September, indicating stores closed due to refurbishment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dM1r-s8NzCQW"
      },
      "outputs": [],
      "source": [
        "sns.scatterplot(x=\"Customers\",y=\"Sales\",data=df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6UsnMABzWOE"
      },
      "source": [
        "####Observation:\n",
        "Sales and Customer scatter plot shows a direct positive relation between them with a few outliers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3kAi1TUzO-6"
      },
      "outputs": [],
      "source": [
        "#scatterplot of Competition Distance and Sales\n",
        "sns.scatterplot(x=df['CompetitionDistance'], y=df['Sales'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0B4vPpwzklc"
      },
      "source": [
        "####Observation:\n",
        "From the above scatter plot it can be observed that mostly the competitor stores weren't that far from each other and the stores densely located near each other saw more sales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVKB59yDzcQ2"
      },
      "outputs": [],
      "source": [
        "#distribution plot of Sales, as expected positively skewed\n",
        "sns.distplot(x=df['Sales'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UFMk2jtz5pf"
      },
      "source": [
        "####Observation:\n",
        "The drop in sales indicates the 0 sales accounting to the stores temporarily closed due to refurbishment. This drop was also seen in the Sales over the years plot earlier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPtdlQ_I0Ctx"
      },
      "source": [
        "###Correlation Matrix\n",
        "Correlation is a statistical term used to measure the degree in which two variables move in relation to each other. A perfect positive correlation means that the correlation coefficient is exactly 1. This implies that as one variable moves, either up or down, the other moves in the same direction. A perfect negative correlation means that two variables move in opposite directions, while a zero correlation implies no linear relationship at all.\n",
        "\n",
        "By checking the correlation the factors affecting sales can be figured out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krymnyVU1sfG"
      },
      "outputs": [],
      "source": [
        "#we need only meaningful numeric columns here, let's drop the unnecessary to get a clear picture\n",
        "columns_to_drop = ['Store', 'Year', 'WeekOfYear', 'DayOfYear']\n",
        "corr_df = df.drop(columns = columns_to_drop, axis =1)\n",
        "corr_df['StateHoliday'].replace({'a':1, 'b':1,'c':1}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6T5cczaJzqPq"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(16,10))\n",
        "sns.heatmap(corr_df.corr(), cmap=\"coolwarm\", annot=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJbzAzUC27yI"
      },
      "source": [
        "####Observation:\n",
        "* Day of the week has a negative correlation indicating low sales as the weekends, and promo, customers and open has positive correlation.\n",
        "* State Holiday has a negative correlation suggesting that stores are mostly closed on state holidays indicating low sales.\n",
        "* CompetitionDistance showing negative correlation suggests that as the distance increases sales reduce, which was also observed through the scatterplot earlier.\n",
        "* There's multicollinearity involved in the dataset as well. The features telling the same story like Promo2, Promo2 since week and year are showing multicollinearity.\n",
        "* The correlation matrix is agreeing with all the observations done earlier while exploring through barplots and scatterplots.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QPBu_CS3B6t"
      },
      "source": [
        "###EDA Conclusions:\n",
        "* There's a positive correlation between customers and sales which is explanatory.\n",
        "\n",
        "* Here it can be deduced that there were more sales on Monday, probably because shops generally remain closed on Sundays which had the lowest sales in a week. \n",
        "\n",
        "* The positive effect of promotion on Customers and Sales is observable. \n",
        "* It is clear that most of the stores remain closed during State and School Holidays. \n",
        "But it is important to note that more stores were open on School Holidays than on State Holidays and hence had more sales than State Holidays.\n",
        "\n",
        "* Based on the above findings it seems that there are quite a lot of opportunities in store type 'b' & 'd' as they had more number of customers per store and more sales per customer, respectively. Store type a & c are quite similar in terms of \"per customer and per store\" sales numbers and just because the majority of the stores were of these kinds, they had the best overall revenue numbers. On the other hand, store type b were very few in number and even then they had better average sales than others.\n",
        "* Earlier, it was observed that only store type b had all three kinds of assortment levels and rest of the store types had two of them. It seems that in some b type stores the products were different as compared to others because the revenue per store is significantly more than the others. \n",
        "\n",
        "* When comparing the sales of the three years, it is observable that sales increase by the end of the year indicating that people shop more before the holidays. All the stores showed Christmas seasonality.\n",
        "The second thing to notice was that sales dropped for a few months in 2014 accounting for the stores closed due to refurbishment.\n",
        "\n",
        "* Most stores have competition distance within the range of 0 to 10 kms and had more sales than stores far away.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atHu2na18CO9"
      },
      "source": [
        "##Feature Engineering\n",
        "Feature engineering consists of creation, transformation, extraction, and selection of features, also known as variables, that are most conducive to creating an accurate ML algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dj9axcy0SJM"
      },
      "outputs": [],
      "source": [
        "#no of observations for closed stores with 0 sales\n",
        "(df[df.Open == 0]).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBYkH3OM8fv1"
      },
      "source": [
        "######It is mentioned in the problem statement that some stores were temporarily closed for refurbishment and hence did not generate any sales. This was also indicated in the barplot of Open vs Sales. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uy753W9L8Ufp"
      },
      "outputs": [],
      "source": [
        "df[df.Open != 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKcesSfW9DIS"
      },
      "outputs": [],
      "source": [
        "#since the stores closed had 0 sale value; removing the irrelevant part\n",
        "df1 = df[df.Open != 0]\n",
        "df1.drop('Open', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head()"
      ],
      "metadata": {
        "id": "4E3F1IxS-DQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#changing into boolean \n",
        "df1['StateHoliday'].replace({'a':1, 'b':1,'c':1}, inplace=True)"
      ],
      "metadata": {
        "id": "dcslzflE_lok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#combining competition open since month and year into total months\n",
        "df1['CompetitionOpen'] = (df1['Year'] - df1['CompetitionOpenSinceYear'])*12 + (df1['Month'] - df1['CompetitionOpenSinceMonth'])\n",
        "#correcting the neg values\n",
        "df1['CompetitionOpen'] = df1['CompetitionOpen'].apply(lambda x:0 if x < 0 else x)\n",
        "#dropping both the columns\n",
        "df1.drop(['CompetitionOpenSinceMonth','CompetitionOpenSinceYear'], axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "CP-4fFkYAgmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#changing promo2 features into meaningful inputs\n",
        "#combining promo2 to total months\n",
        "df1['Promo2Open'] = (df1['Year'] - df1['Promo2SinceYear'])*12 + (df1['WeekOfYear'] - df1['Promo2SinceWeek'])*0.230137\n",
        "\n",
        "#correcting the neg values\n",
        "df1['Promo2Open'] = df1['Promo2Open'].apply(lambda x:0 if x < 0 else x)*df1['Promo2']\n",
        "\n",
        "#creating a feature for promo interval and checking if promo2 was running in the sale month\n",
        "def promo2running(df):\n",
        "  month_dict = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun', 7:'Jul', 8:'Aug', 9:'Sept', 10:'Oct', 11:'Nov', 12:'Dec'}\n",
        "  try:\n",
        "    months = df['PromoInterval'].split(',')\n",
        "    if df['Month'] and month_dict[df['Month']] in months:\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "  except Exception:\n",
        "    return 0\n",
        "\n",
        "#Applying \n",
        "df1['Promo2running'] = df1.apply(promo2running,axis=1)*df1['Promo2']\n",
        "\n",
        "#Dropping unecessary columns\n",
        "df1.drop(['Promo2SinceYear','Promo2SinceWeek','PromoInterval'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "KN1_R2Z_AlRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#setting date and store as index\n",
        "df1.set_index(['Date','Store'],inplace=True)\n",
        "#sorting index following the time series\n",
        "df1.sort_index(inplace=True)"
      ],
      "metadata": {
        "id": "9KECS2DzA8-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head()"
      ],
      "metadata": {
        "id": "CuiniAuzBB1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Outlier Detection:"
      ],
      "metadata": {
        "id": "Blss-ZAILS29"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Outliers and Z score:\n",
        "In statistics, an outlier is a data point that differs significantly from other observations. Outliers can occur by chance in any distribution, but they often indicate either measurement error or that the population has a heavy-tailed distribution.\n",
        "\n",
        "Z-score is a statistical measure that tells you how far is a data point from the rest of the dataset. In a more technical term, Z-score tells how many standard deviations away a given observation is from the mean.\n",
        "\n",
        "z = (x-mean)/standard deviation"
      ],
      "metadata": {
        "id": "Aan8M--RLKfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code to seperate outliers\n",
        "mean_sales = np.mean(df1['Sales']) #mean\n",
        "sd_sales = np.std(df1['Sales'])   #standard deviation\n",
        "#More than 3 standard deviation is an outlier\n",
        "threshold = 3\n",
        "#code to identify them\n",
        "outliers = []\n",
        "for value in df1['Sales']:\n",
        "    z_score = (value-mean_sales)/sd_sales\n",
        "    if z_score > threshold:\n",
        "        outliers.append(value)\n",
        "#total no of outliers        \n",
        "print(f'Total number of Outliers present in the Sales column are {len(outliers)}.')\n",
        "#plotting the outlier distribution\n",
        "sns.distplot(x=outliers).set(title='Outliers Distribution')"
      ],
      "metadata": {
        "id": "ztQVXM4aLg18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data points with sales value higher than 28000 are very low and hence they can be considered as outliers. The percentage of outliers in our dataset"
      ],
      "metadata": {
        "id": "jydDn_s2L-bC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#percentage of sales greater than 28000 \n",
        "sales_outliers = df1.loc[df1['Sales']>28000]\n",
        "percentage_of_outliers = (len(sales_outliers)/len(df1))*100\n",
        "#print\n",
        "print(f'The percentage of observations of sales greater than 28000 are {percentage_of_outliers}')"
      ],
      "metadata": {
        "id": "5avCKVXON54s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#exploring the reasons behind this behaviour\n",
        "sales_outliers.head()"
      ],
      "metadata": {
        "id": "RdjWUvghN_4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lets see which stores were open on Sunday in the outliers dataframe\n",
        "#store 262\n",
        "sales_outliers.loc[sales_outliers['DayOfWeek']==7]"
      ],
      "metadata": {
        "id": "zwSWy3HcPIG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#let's explore store type and Day Of week\n",
        "sns.barplot(x=df1['DayOfWeek'],y=df1[\"Sales\"],hue=df1['StoreType'])"
      ],
      "metadata": {
        "id": "z4YNZ0ksPelQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Observation:\n",
        "Some interesting insights can be drawn from these outliers dataframe:\n",
        "* First thing that comes to notice is the DayOfWeek for Store 262. It's sunday and it has high sales and it's of the store type B. \n",
        "* All other data points had promotion going on and they had a high number of Customers as well indicating no absurd behavior.\n",
        "* It can be well established that the outliers are showing this behavior for the stores with promotion = 1 and store type B. It would not be wise to treat them because the reasons behind this behavior seems fair.\n"
      ],
      "metadata": {
        "id": "qVoSXt_ZOH60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#let's verify in the full dataset\n",
        "df1.loc[(df1['DayOfWeek']==7) & (df1['StoreType']=='b')]"
      ],
      "metadata": {
        "id": "JXRClm2GRBUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Observation:\n",
        "* This suggests that store type b had high sales almost all week. No store of type C was open on Sunday.\n",
        "* Being open 24*7 along with all kinds of assortments available is probably the reason why it had higher average sales than any other store type.\n"
      ],
      "metadata": {
        "id": "jZqp6vPgRnzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#let's check if the sales value was 0 even when there was not a sunday, state or school holiday\n",
        "df1.loc[(df1['Sales']==0) & (df1['StateHoliday']==0) & (df1['SchoolHoliday']==0) & (df1['SchoolHoliday'] != 7)].head()"
      ],
      "metadata": {
        "id": "rUO-RONURy2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#these are some strange cases where no sales were recorded even when the stores should have been open\n",
        "#even when many of them were promotion positive\n",
        "df1.drop(df1.loc[(df1['Sales']==0) & (df1['StateHoliday']==0) & (df1['SchoolHoliday']==0) & (df1['SchoolHoliday'] != 7)].index,inplace=True)"
      ],
      "metadata": {
        "id": "txzfxnrgSRct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.shape"
      ],
      "metadata": {
        "id": "nV3NNSvjSYzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Outlier Treatment**\n",
        "\n",
        "- It can be well established that the outliers are showing this behaviour for the stores with promotion = 1 and store type B. It would not be wise to treat them because the reasons behind this behaviour seems fair and important from the business point of view.\n",
        "- The primary reasons for the behaviour are promotion and store type B.\n",
        "- If the outliers are a valid occurrence it would be wise not to treat them by deleting or manipulating them especially when we have established the ups and downs of the target variable in relation to the other features. It is well established that there is seasonality involved and no linear relationship is possible to fit. For these kinds of datasets tree based machine learning algorithms are used which are robust to outlier effect."
      ],
      "metadata": {
        "id": "ZyIp6gg8SjGp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Features Scaling"
      ],
      "metadata": {
        "id": "vrxTnT7PTNtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing minmax scaler\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "86DQl11STRWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1"
      ],
      "metadata": {
        "id": "Z2szTMbjTWoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#unscaled csv\n",
        "cleaned_unscaled_data = df1.to_csv(\"/content/drive/MyDrive/Alma Better/Projects/SML Regression - Retail Sales Prediction/Cleaned data/Cleaned_Unscaled_data.csv\")"
      ],
      "metadata": {
        "id": "citt98gjVia7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2=df1.copy()"
      ],
      "metadata": {
        "id": "EO2d_dCwYdSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2"
      ],
      "metadata": {
        "id": "fkDCaV6LYfpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fitting numerical columns\n",
        "numerical_cols = ['Customers','CompetitionDistance','Year','Month','WeekOfYear','DayOfYear','CompetitionOpen','Promo2Open','Sales']\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(df2[numerical_cols])\n",
        "df2[numerical_cols] = scaler.transform(df2[numerical_cols])"
      ],
      "metadata": {
        "id": "XMpadFZGYgwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.head()"
      ],
      "metadata": {
        "id": "4OnlQr__ZYOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Categorical Features Encoding"
      ],
      "metadata": {
        "id": "eWq9jPwsp-ly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "Y2bwyCDdqCqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#categorical features\n",
        "categorical_cols = ['DayOfWeek', 'StoreType', 'Assortment']"
      ],
      "metadata": {
        "id": "paE-pWSeqW-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fit encoder\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "encoder.fit(df2[categorical_cols])\n",
        "encoded_features = list(encoder.get_feature_names(categorical_cols))\n",
        "df2[encoded_features] = encoder.transform(df2[categorical_cols])"
      ],
      "metadata": {
        "id": "R6UCLmeyqXsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.head()"
      ],
      "metadata": {
        "id": "uXnEN02WqaKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#drop columns\n",
        "df2.drop(categorical_cols,axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "j7MCyOrLqjPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sales should be the last col\n",
        "columns=list(df2.columns)\n",
        "columns.remove('Sales')\n",
        "columns.append('Sales')\n",
        "df2=df2[columns]"
      ],
      "metadata": {
        "id": "8-PrNP_3qrdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check\n",
        "df2.head(1)"
      ],
      "metadata": {
        "id": "mClOQDrdquQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Modeling\n",
        "**Factors affecting in choosing the model:**\n",
        " \n",
        "Determining which algorithm to use depends on many factors like the problem statement and the kind of output you want, type and size of the data, the available computational time, number of features, and observations in the data."
      ],
      "metadata": {
        "id": "GSRm__0kq5r4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Train-Test Split"
      ],
      "metadata": {
        "id": "rQpZ0uIjrbtx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2.head()"
      ],
      "metadata": {
        "id": "iiUKM34qrr8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.tail()"
      ],
      "metadata": {
        "id": "hPQmsbr9rtzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#slicing the most recent six weeks and creating train and test set\n",
        "#train\n",
        "start_train = pd.to_datetime(\"2013-01-01\")\n",
        "end_train = pd.to_datetime(\"2015-06-14\")\n",
        "df_train = df2.loc[start_train:end_train]\n",
        "#test\n",
        "start_test = pd.to_datetime(\"2015-06-15\")\n",
        "end_test = pd.to_datetime(\"2015-07-31\")\n",
        "df_test = df2.loc[start_test:end_test]"
      ],
      "metadata": {
        "id": "ciqcfhNLrwj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#X and y split for train and test\n",
        "X_train = df_train.drop('Sales',axis=1)\n",
        "y_train = df_train[['Sales']]\n",
        "X_test = df_test.drop('Sales',axis=1)\n",
        "y_test = df_test[['Sales']]\n",
        "print(f'The shape of X_train is: {X_train.shape}')\n",
        "print(f'The shape of y_train is: {y_train.shape}')\n",
        "print(f'The shape of X_test is: {X_test.shape}')\n",
        "print(f'The shape of y_test is: {y_test.shape}')"
      ],
      "metadata": {
        "id": "xbrsU3hHuRen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Linear Regression"
      ],
      "metadata": {
        "id": "9BG8wVzyw0Rk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "reg = LinearRegression().fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "xMz-lCEm1PmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#metrics import\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score"
      ],
      "metadata": {
        "id": "yiq0BN7w2Gbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Columns needed to compare metrics\n",
        "comparison_columns = ['Model_Name', 'Train_MAE', 'Train_MSE', 'Train_RMSE', 'Train_R2', 'Train_Adj_R2' ,'Test_MAE', 'Test_MSE', 'Test_RMSE', 'Test_R2', 'Test_Adj_R2']"
      ],
      "metadata": {
        "id": "-S9dTjXrOm7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to evaluate the model\n",
        "def model_evaluation(model_name,model_variable,X_train,y_train,X_test,y_test):\n",
        "  ''' This function predicts and evaluates various models for regression algorithms, visualizes results '''\n",
        "      \n",
        "  #making predictions\n",
        "  y_pred_train = model_variable.predict(X_train)\n",
        "  y_pred_test = model_variable.predict(X_test)\n",
        "\n",
        "  # Plot the test results\n",
        "  a = y_test.copy()\n",
        "  a['Pred Sales'] = y_pred_test.tolist()\n",
        "  df_plot = a.reset_index(level=['Date'])\n",
        "  plot = df_plot.groupby('Date')['Sales','Pred Sales'].sum()\n",
        "  sns.lineplot(data = plot)\n",
        "  plt.ylabel(\"Total Sales and Predicted Sales\")\n",
        "  plt.xticks(rotation = 25)\n",
        "\n",
        "  #calculate metrics and print the results for test set\n",
        "  #Mean Absolute Error or MAE\n",
        "  MAE_train = round(mean_absolute_error(y_train,y_pred_train),6)\n",
        "  MAE_test = round(mean_absolute_error(y_test,y_pred_test),6)\n",
        "  #Mean Squared Error or MSE\n",
        "  MSE_train = round(mean_squared_error(y_train,y_pred_train),6)\n",
        "  MSE_test = round(mean_squared_error(y_test,y_pred_test),6)\n",
        "  #Root Mean Squared Error or RMSE\n",
        "  RMSE_train = round(mean_squared_error(y_train,y_pred_train,squared=False),6)\n",
        "  RMSE_test = round(mean_squared_error(y_test,y_pred_test,squared=False),6)\n",
        "  #R2\n",
        "  R2_train = round(r2_score(y_train, y_pred_train),6)\n",
        "  R2_test = round(r2_score(y_test, y_pred_test),6)\n",
        "  #Adjusted R2\n",
        "  Adj_r2_train = round(1 - (1-r2_score(y_train, y_pred_train)) * (len(y_train)-1)/(len(y_train)-X_train.shape[1]-1),6)\n",
        "  Adj_r2_test = round(1 - (1-r2_score(y_test, y_pred_test)) * (len(y_test)-1)/(len(y_test)-X_test.shape[1]-1),6)\n",
        "  #printing train results\n",
        "  print(f'The MAE for the Training set is {MAE_train}')\n",
        "  print(f'The MSE for the Training set is {MSE_train}')\n",
        "  print(f'The RMSE for the Training set is {RMSE_train}')\n",
        "  print(f'The R2 for the Training set is {R2_train}')\n",
        "  print(f'The Adjusted R2 for the Training set is {Adj_r2_train}')\n",
        "  print(\"--------------------------\")\n",
        "  print(f'The MAE for the validation set is {MAE_test}')\n",
        "  print(f'The MSE for the validation set is {MSE_test}')\n",
        "  print(f'The RMSE for the validation set is {RMSE_test}')\n",
        "  print(f'The R2 for the validation set is {R2_test}')\n",
        "  print(f'The Adjusted R2 for the validation set is {Adj_r2_test}')\n",
        "\n",
        "    #Saving our results\n",
        "  global comparison_columns\n",
        "  metric_scores = [model_name,MAE_train,MSE_train,RMSE_train,R2_train,Adj_r2_train,MAE_test,MSE_test,RMSE_test,R2_test,Adj_r2_test]\n",
        "  final_dict = dict(zip(comparison_columns,metric_scores))\n",
        "  return [final_dict]"
      ],
      "metadata": {
        "id": "miWRbmuG041Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to create the comparison table\n",
        "final_list = []\n",
        "def add_list_to_final_df(dict_list):\n",
        "  global final_list\n",
        "  for elem in dict_list:\n",
        "    final_list.append(elem)\n",
        "  global comparisons_df\n",
        "  comparisons_df = pd.DataFrame(final_list, columns= comparison_columns)"
      ],
      "metadata": {
        "id": "1E-8zCogCUg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LinearRegression = model_evaluation('LinearRegression',reg,X_train,y_train,X_test,y_test)"
      ],
      "metadata": {
        "id": "WQAHFWGUBpyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#add results to comparison df\n",
        "add_list_to_final_df(LinearRegression)"
      ],
      "metadata": {
        "id": "B2twdZXyCKRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comparisons_df"
      ],
      "metadata": {
        "id": "FJD__Hl5CZKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Observation:\n",
        "- In Linear Regression R2 score and adjusted R2 score is very less. So we need to move further models like Decision Tree."
      ],
      "metadata": {
        "id": "RpdTJQ5OeX-s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Tree"
      ],
      "metadata": {
        "id": "ZrcH-ueYe6SN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing libraries\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "#fitting decision tree\n",
        "dt_basic = DecisionTreeRegressor(random_state=42)\n",
        "dt_basic.fit(X_train,y_train)\n",
        "#decision tree evaluation\n",
        "decision_tree = model_evaluation('Decision Tree Regressor',dt_basic,X_train,y_train,X_test,y_test)"
      ],
      "metadata": {
        "id": "lEpSLc6m0-kQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#add results to comparison df\n",
        "add_list_to_final_df(decision_tree)"
      ],
      "metadata": {
        "id": "YeXkRkZUCnPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comparisons_df\n"
      ],
      "metadata": {
        "id": "sGIp-ySJCqLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Observation:\n",
        "- The Decision tree was chosen considering our features were mostly categorical with few having continuous importance. The above results show that a simple decision tree is performing pretty well on the validation set but it has completely overfitted the train set. It's better to have a much more generalized model for future data points. By using hyper parameter tuning we can solve this issue."
      ],
      "metadata": {
        "id": "tt3h2OOB2wxr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Random Forest"
      ],
      "metadata": {
        "id": "PSG91bZE3Amb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "metadata": {
        "id": "ZTOUzU4C3JkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fitting\n",
        "random_forest = RandomForestRegressor(n_estimators=50,random_state=42)\n",
        "random_forest.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "YG8boEH73y4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model evaluation\n",
        "random_f = model_evaluation('Random Forest Regressor',random_forest,X_train,y_train,X_test,y_test)"
      ],
      "metadata": {
        "id": "20oPrARq30_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#add results to comparison df\n",
        "add_list_to_final_df(random_f)"
      ],
      "metadata": {
        "id": "4jdso9kn92rI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comparisons_df"
      ],
      "metadata": {
        "id": "9HIG0VLKHk8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#parameters used in random forest\n",
        "print('Parameters currently in use:')\n",
        "print(random_forest.get_params())"
      ],
      "metadata": {
        "id": "2r_Pdfa4_l5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Observation:\n",
        "Random Forest Regressor results were much better than Linear Regression and Desicion Tree. Next we'll try to tune the hyperparameters and check the results"
      ],
      "metadata": {
        "id": "y9oAgLba_xMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a csv file for the cleaned dataset\n",
        "# Rossmann sales prediction to be continued in the next notebook\n",
        "cleaned_data = df2.to_csv(\"/content/drive/MyDrive/Alma Better/Projects/SML Regression - Retail Sales Prediction/Cleaned data/Cleaned_data.csv\")\n",
        "#creating a csv file for the comparison dataframe\n",
        "results = comparisons_df.to_csv(\"/content/drive/MyDrive/Alma Better/Projects/SML Regression - Retail Sales Prediction/Cleaned data/results.csv\")"
      ],
      "metadata": {
        "id": "CcBn25ULQrRa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Retail Sales Prediction -Capstone Project( Part-1).ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}